{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../general')\n",
    "from pool import Pool\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
    "from collections import Counter\n",
    "from metric import metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pool = Pool('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    train_pool, test_pool = pool.train_test_split()\n",
    "    train_features = np.concatenate(\n",
    "        (train_pool.features, np.reshape(train_pool.positions, (-1, 1))),\n",
    "        axis=1\n",
    "    )\n",
    "    test_features = np.concatenate(\n",
    "        (test_pool.features, np.reshape(test_pool.positions, (-1, 1))),\n",
    "        axis=1\n",
    "    )\n",
    "    need_vertical_labels_train = np.array([\n",
    "        1 if label == 3 else 0\n",
    "        for label in train_pool.classification_labels\n",
    "    ])\n",
    "    need_vertical_labels_test = np.array([\n",
    "        1 if label == 3 else 0\n",
    "        for label in test_pool.classification_labels\n",
    "    ])\n",
    "\n",
    "    need_vertical_model = LogisticRegression()\n",
    "    need_vertical_model.fit(train_features, need_vertical_labels_train)\n",
    "    need_vertical = need_vertical_model.predict(test_features)\n",
    "\n",
    "    positive_train_features = train_features[np.array(train_pool.classification_labels) == 3]\n",
    "    positive_train_target = train_pool.targets[np.array(train_pool.classification_labels) == 3]\n",
    "\n",
    "    postition_score_model = xgb.XGBRegressor()\n",
    "    postition_score_model.fit(positive_train_features, positive_train_target)\n",
    "\n",
    "    prediction = []\n",
    "    for features, need_vertical_bool in zip(test_features, need_vertical):\n",
    "        if not need_vertical_bool:\n",
    "            prediction.append(100)\n",
    "        else:\n",
    "            max_score = -100\n",
    "            best_position = -100\n",
    "            for position in test_pool.POSITIONS:\n",
    "                new_score = postition_score_model.predict([list(features)[:-1] + [position]])[0]\n",
    "                if new_score > max_score:\n",
    "                    max_score = new_score\n",
    "                    best_position = position\n",
    "            prediction.append(best_position)\n",
    "    return metric(prediction, test_pool.positions, test_pool.targets, test_pool.probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [test() for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0013959389985173166"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00837579537187419"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0020257822163923284,\n",
       " -0.004068537727718805,\n",
       " 0.007653224705637274,\n",
       " 0.0056002487968361886,\n",
       " -0.015130559278948703,\n",
       " -0.0073836354783455285,\n",
       " 0.006975416870619118,\n",
       " -0.0398158335475041,\n",
       " 0.0030803867507852916,\n",
       " 0.0036065758325915273,\n",
       " -0.0003487648234013926,\n",
       " 0.0026163871762828273,\n",
       " 0.000510057797142641,\n",
       " 0.004252853710454962,\n",
       " 0.0007780944752081662,\n",
       " -0.001561648014472906,\n",
       " -0.002299496954467789,\n",
       " 0.003969255754882425,\n",
       " 0.0001859647298928746,\n",
       " 0.005690154058280687,\n",
       " -0.005877287511056444,\n",
       " -0.00022228821934383445,\n",
       " -0.04901391587971903,\n",
       " 0.00017400670398030028,\n",
       " 0.0036882552818810017,\n",
       " 0.000979104607055473,\n",
       " -0.009606406764351769,\n",
       " -0.005715364894409975,\n",
       " -0.003291282668671489,\n",
       " -0.002085084440032425,\n",
       " 0.0032012677092968073,\n",
       " -0.022435190641365278,\n",
       " 0.0021301674723451405,\n",
       " -0.0012719857758875224,\n",
       " -0.0008151921903931775,\n",
       " -0.0009340035374503811,\n",
       " 0.00572759215166137,\n",
       " -0.009827239044136985,\n",
       " 0.002304278426380904,\n",
       " 0.00400459336706308,\n",
       " -1.1032873320223073e-05,\n",
       " -0.0009702924827308527,\n",
       " 0.0018748489549066992,\n",
       " -0.000737863455430082,\n",
       " -0.006341597766655489,\n",
       " -0.007979966677649065,\n",
       " -0.00015940241551790175,\n",
       " -0.004070859379767484,\n",
       " 0.003141882101119883,\n",
       " -0.003985016922314307,\n",
       " 0.003244585685265435,\n",
       " 0.0013843119971951826,\n",
       " 0.0057739966091917404,\n",
       " 0.0008885528488564696,\n",
       " 0.0005434876851242843,\n",
       " -0.0005782660948536361,\n",
       " 0.002255407468325428,\n",
       " 0.005269878621176541,\n",
       " 0.0012570728266913494,\n",
       " 0.003515964792540562,\n",
       " 0.0008321544016435894,\n",
       " 0.004899283995772614,\n",
       " 0.0006554572273132962,\n",
       " -0.027026824396246454,\n",
       " 0.003609088031808618,\n",
       " -0.0021492442908969843,\n",
       " -0.0064053006654000285,\n",
       " -0.0008192793172838017,\n",
       " -0.0030923123520652787,\n",
       " -0.0028852181515489723,\n",
       " 0.004100072699902922,\n",
       " 0.0018911812611434647,\n",
       " 0.004138936709216319,\n",
       " 0.00034649411491209365,\n",
       " -0.00606269999814107,\n",
       " 0.00590967621048341,\n",
       " -0.008131357380727603,\n",
       " 0.001443163732086722,\n",
       " -0.0025762432880372783,\n",
       " 0.005925918452460622,\n",
       " -0.0022195650654609042,\n",
       " 0.003677399114273052,\n",
       " 0.003080648960558833,\n",
       " 0.006081456835010953,\n",
       " 0.008563945903662665,\n",
       " -0.003958950544269709,\n",
       " -0.011057852157053613,\n",
       " 0.0017496871870242806,\n",
       " 0.0021949719018839017,\n",
       " -0.0009549044585589177,\n",
       " -0.004937626266581707,\n",
       " -0.002702824767196858,\n",
       " 0.0027356817300573737,\n",
       " -0.008743780227474851,\n",
       " 0.001381883413924152,\n",
       " 0.0011397272046726845,\n",
       " 0.005560106400646191,\n",
       " -0.0007538126931023368,\n",
       " 0.00200940033321913,\n",
       " -0.008808082378509613]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

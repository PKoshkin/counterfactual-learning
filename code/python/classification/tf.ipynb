{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../general')\n",
    "from pool import Pool\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool('../data')\n",
    "train_pool, test_pool = pool.train_test_split()\n",
    "train_features = np.concatenate(\n",
    "    (train_pool.features, np.reshape(train_pool.positions, (-1, 1))),\n",
    "    axis=1\n",
    ")\n",
    "train_labels = train_pool.classification_labels\n",
    "test_features = np.concatenate(\n",
    "    (test_pool.features, np.reshape(test_pool.positions, (-1, 1))),\n",
    "    axis=1\n",
    ")\n",
    "test_labels = test_pool.classification_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interactive_session = tf.InteractiveSession()\n",
    "train_labels = tf.one_hot(train_labels, 2).eval()\n",
    "test_labels = tf.one_hot(test_labels, 2).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "num_features = np.shape(train_features)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf.get_variable(\n",
    "    \"weights\", shape=(num_features, num_classes),\n",
    "    initializer=tf.glorot_uniform_initializer()\n",
    ")\n",
    "bias = tf.get_variable(\n",
    "    \"bias\", shape=(num_classes,),\n",
    "    initializer=tf.glorot_uniform_initializer()\n",
    ")\n",
    "input_X = tf.placeholder('float32', shape=(None, num_features))\n",
    "input_y = tf.placeholder('float32', shape=(None, num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_y = tf.nn.softmax(tf.matmul(input_X, weights) + bias)\n",
    "loss = -tf.reduce_mean(input_y * tf.log(predicted_y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss, var_list=[weights, bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(\n",
    "    tf.cast(tf.equal(tf.argmax(predicted_y, 1),\n",
    "    tf.argmax(input_y, 1)), \"float\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at iter 0:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 1:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 2:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 3:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 4:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 5:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 6:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 7:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 8:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 9:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 10:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 11:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 12:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 13:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 14:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 15:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 16:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 17:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 18:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 19:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 20:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 21:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 22:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 23:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 24:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 25:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 26:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 27:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 28:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 29:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 30:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 31:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 32:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 33:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 34:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 35:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 36:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 37:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 38:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 39:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 40:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 41:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 42:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 43:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 44:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 45:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 46:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 47:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 48:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 49:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 50:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 51:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 52:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 53:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 54:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 55:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 56:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 57:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 58:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 59:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 60:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 61:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 62:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 63:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 64:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 65:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 66:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 67:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 68:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 69:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 70:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 71:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 72:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 73:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 74:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 75:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 76:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 77:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 78:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 79:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 80:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 81:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 82:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 83:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 84:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 85:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 86:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 87:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 88:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 89:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 90:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 91:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 92:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 93:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 94:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 95:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 96:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 97:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 98:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 99:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 100:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 101:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 102:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 103:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 104:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 105:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 106:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 107:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 108:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 109:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 110:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 111:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 112:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 113:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 114:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 115:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 116:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 117:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 118:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 119:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 120:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 121:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 122:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 123:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 124:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 125:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 126:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 127:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 128:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 129:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 130:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 131:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 132:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 133:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 134:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 135:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 136:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at iter 137:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 138:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 139:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 140:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 141:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 142:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 143:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 144:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 145:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 146:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 147:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 148:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 149:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 150:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 151:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 152:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 153:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 154:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 155:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 156:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 157:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 158:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 159:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 160:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 161:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 162:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 163:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 164:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 165:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 166:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 167:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 168:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 169:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 170:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 171:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 172:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 173:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 174:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 175:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 176:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 177:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 178:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 179:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 180:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 181:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 182:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 183:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 184:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 185:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 186:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 187:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 188:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 189:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 190:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 191:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 192:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 193:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 194:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 195:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 196:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 197:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 198:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 199:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 200:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 201:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 202:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 203:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 204:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 205:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 206:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 207:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 208:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 209:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 210:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 211:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 212:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 213:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 214:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 215:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 216:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 217:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 218:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 219:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 220:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 221:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 222:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 223:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 224:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 225:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 226:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 227:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 228:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 229:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 230:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 231:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 232:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 233:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 234:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 235:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 236:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 237:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 238:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 239:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 240:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 241:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 242:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 243:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 244:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 245:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 246:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 247:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 248:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 249:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 250:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 251:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 252:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 253:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 254:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 255:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 256:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 257:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 258:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 259:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 260:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 261:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 262:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 263:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 264:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 265:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 266:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 267:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 268:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 269:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 270:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 271:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at iter 272:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 273:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 274:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 275:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 276:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 277:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 278:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 279:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 280:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 281:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 282:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 283:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 284:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 285:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 286:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 287:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 288:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 289:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 290:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 291:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 292:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 293:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 294:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 295:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 296:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 297:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 298:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 299:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 300:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 301:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 302:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 303:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 304:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 305:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 306:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 307:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 308:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 309:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 310:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 311:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 312:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 313:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 314:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 315:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 316:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 317:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 318:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 319:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 320:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 321:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 322:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 323:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 324:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 325:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 326:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 327:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 328:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 329:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 330:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 331:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 332:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 333:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 334:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 335:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 336:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 337:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 338:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 339:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 340:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 341:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 342:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 343:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 344:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 345:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 346:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 347:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 348:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 349:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 350:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 351:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 352:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 353:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 354:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 355:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 356:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 357:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 358:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 359:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 360:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 361:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 362:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 363:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 364:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 365:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 366:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 367:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 368:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 369:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 370:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 371:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 372:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 373:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 374:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 375:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 376:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 377:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 378:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 379:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 380:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 381:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 382:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 383:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 384:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 385:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 386:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 387:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 388:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 389:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 390:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 391:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 392:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 393:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 394:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 395:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 396:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 397:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 398:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 399:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 400:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 401:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 402:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 403:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 404:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 405:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 406:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at iter 407:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 408:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 409:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 410:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 411:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 412:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 413:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 414:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 415:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 416:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 417:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 418:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 419:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 420:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 421:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 422:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 423:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 424:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 425:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 426:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 427:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 428:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 429:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 430:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 431:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 432:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 433:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 434:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 435:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 436:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 437:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 438:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 439:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 440:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 441:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 442:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 443:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 444:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 445:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 446:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 447:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 448:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 449:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 450:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 451:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 452:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 453:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 454:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 455:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 456:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 457:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 458:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 459:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 460:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 461:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 462:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 463:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 464:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 465:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 466:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 467:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 468:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 469:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 470:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 471:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 472:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 473:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 474:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 475:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 476:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 477:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 478:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 479:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 480:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 481:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 482:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 483:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 484:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 485:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 486:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 487:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 488:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 489:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 490:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 491:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 492:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 493:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 494:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 495:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 496:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 497:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 498:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "loss at iter 499:nan\n",
      "train auc: 0.963746\n",
      "test auc: 0.9623333\n",
      "resulting weights:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1053 into shape (8,newaxis)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d5fdfd178ed0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resulting weights:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 1053 into shape (8,newaxis)"
     ]
    }
   ],
   "source": [
    "for i in range(500):\n",
    "    sess.run(optimizer, {input_X: train_features, input_y: train_labels})\n",
    "    loss_i = sess.run(loss, {input_X: train_features, input_y: train_labels})\n",
    "\n",
    "    print(\"loss at iter %i:%.4f\" % (i, loss_i))\n",
    "\n",
    "    print(\n",
    "        \"train auc:\",\n",
    "        sess.run(accuracy, feed_dict={input_X: train_features, input_y: train_labels})\n",
    "    )\n",
    "    print(\n",
    "        \"test auc:\",\n",
    "        sess.run(accuracy, feed_dict={input_X: test_features, input_y: test_labels})\n",
    "    )\n",
    "\n",
    "print(\"resulting weights:\")\n",
    "plt.imshow(sess.run(weights)[:, 0].reshape(8,-1))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

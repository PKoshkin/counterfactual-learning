{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../general')\n",
    "from pool import Pool\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pool = Pool('../data')\n",
    "train_pool, test_pool = pool.train_test_split()\n",
    "train_features = np.concatenate(\n",
    "    (train_pool.features, np.reshape(train_pool.positions, (-1, 1))),\n",
    "    axis=1\n",
    ")\n",
    "train_labels = train_pool.classification_labels\n",
    "test_features = np.concatenate(\n",
    "    (test_pool.features, np.reshape(test_pool.positions, (-1, 1))),\n",
    "    axis=1\n",
    ")\n",
    "test_labels = test_pool.classification_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interactive_session = tf.InteractiveSession()\n",
    "train_labels = tf.one_hot(train_labels, 2).eval()\n",
    "test_labels = tf.one_hot(test_labels, 2).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "num_features = np.shape(train_features)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = tf.get_variable(\n",
    "    \"weights\", shape=(num_features, num_classes),\n",
    "    initializer=tf.glorot_uniform_initializer()\n",
    ")\n",
    "bias = tf.get_variable(\n",
    "    \"bias\", shape=(num_classes,),\n",
    "    initializer=tf.glorot_uniform_initializer()\n",
    ")\n",
    "input_X = tf.placeholder('float32', shape=(None, num_features))\n",
    "input_y = tf.placeholder('float32', shape=(None, num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-10\n",
    "predicted_y = tf.nn.softmax(tf.matmul(input_X, weights) + bias)\n",
    "loss = -tf.reduce_mean(input_y * tf.log(tf.clip_by_value(predicted_y, 0 + eps, 1)))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss, var_list=[weights, bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(\n",
    "    tf.cast(tf.equal(tf.argmax(predicted_y, 1),\n",
    "    tf.argmax(input_y, 1)), \"float\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at iter 0: 0.0538366362452507\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684074\n",
      "loss at iter 1: 0.05382094904780388\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684074\n",
      "loss at iter 2: 0.053805332630872726\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684074\n",
      "loss at iter 3: 0.05378979444503784\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684074\n",
      "loss at iter 4: 0.05377433821558952\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684074\n",
      "loss at iter 5: 0.05375894904136658\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684074\n",
      "loss at iter 6: 0.0537436418235302\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684074\n",
      "loss at iter 7: 0.05372840538620949\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684074\n",
      "loss at iter 8: 0.05371324345469475\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684074\n",
      "loss at iter 9: 0.05369815602898598\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684074\n",
      "loss at iter 10: 0.053683143109083176\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684074\n",
      "loss at iter 11: 0.053668197244405746\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684074\n",
      "loss at iter 12: 0.05365333706140518\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684074\n",
      "loss at iter 13: 0.05363853648304939\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684074\n",
      "loss at iter 14: 0.05362381041049957\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684074\n",
      "loss at iter 15: 0.05360915884375572\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684074\n",
      "loss at iter 16: 0.053594570606946945\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684074\n",
      "loss at iter 17: 0.053580064326524734\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684074\n",
      "loss at iter 18: 0.053565613925457\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684074\n",
      "loss at iter 19: 0.05355124548077583\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684074\n",
      "loss at iter 20: 0.05353694036602974\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684074\n",
      "loss at iter 21: 0.05352270230650902\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684074\n",
      "loss at iter 22: 0.05350853502750397\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684074\n",
      "loss at iter 23: 0.05349443480372429\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684074\n",
      "loss at iter 24: 0.053480397909879684\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684074\n",
      "loss at iter 25: 0.05346643179655075\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684074\n",
      "loss at iter 26: 0.05345253646373749\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684074\n",
      "loss at iter 27: 0.053438700735569\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684074\n",
      "loss at iter 28: 0.053424935787916183\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684074\n",
      "loss at iter 29: 0.05341123044490814\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684074\n",
      "loss at iter 30: 0.053397588431835175\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684074\n",
      "loss at iter 31: 0.05338401719927788\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684074\n",
      "loss at iter 32: 0.05337051302194595\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684074\n",
      "loss at iter 33: 0.053357064723968506\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684074\n",
      "loss at iter 34: 0.05334367975592613\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684074\n",
      "loss at iter 35: 0.05333036184310913\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684074\n",
      "loss at iter 36: 0.0533171072602272\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684074\n",
      "loss at iter 37: 0.05330391228199005\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684074\n",
      "loss at iter 38: 0.05329078435897827\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684074\n",
      "loss at iter 39: 0.05327770859003067\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684074\n",
      "loss at iter 40: 0.05326470360159874\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684074\n",
      "loss at iter 41: 0.05325175076723099\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684074\n",
      "loss at iter 42: 0.05323886126279831\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684074\n",
      "loss at iter 43: 0.053226035088300705\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684074\n",
      "loss at iter 44: 0.053213272243738174\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684074\n",
      "loss at iter 45: 0.053200554102659225\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684074\n",
      "loss at iter 46: 0.05318790674209595\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684074\n",
      "loss at iter 47: 0.053175318986177444\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684074\n",
      "loss at iter 48: 0.05316278338432312\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684074\n",
      "loss at iter 49: 0.05315030738711357\n",
      "train auc: 0.969381\n",
      "test auc: 0.96844447\n",
      "loss at iter 50: 0.0531378872692585\n",
      "train auc: 0.969381\n",
      "test auc: 0.96844447\n",
      "loss at iter 51: 0.0531255304813385\n",
      "train auc: 0.969381\n",
      "test auc: 0.96844447\n",
      "loss at iter 52: 0.05311322957277298\n",
      "train auc: 0.969381\n",
      "test auc: 0.96844447\n",
      "loss at iter 53: 0.05310098081827164\n",
      "train auc: 0.969381\n",
      "test auc: 0.96844447\n",
      "loss at iter 54: 0.05308878794312477\n",
      "train auc: 0.969381\n",
      "test auc: 0.96844447\n",
      "loss at iter 55: 0.05307665839791298\n",
      "train auc: 0.969381\n",
      "test auc: 0.96844447\n",
      "loss at iter 56: 0.05306457728147507\n",
      "train auc: 0.969381\n",
      "test auc: 0.96844447\n",
      "loss at iter 57: 0.05305255204439163\n",
      "train auc: 0.969381\n",
      "test auc: 0.96844447\n",
      "loss at iter 58: 0.05304059013724327\n",
      "train auc: 0.969381\n",
      "test auc: 0.96844447\n",
      "loss at iter 59: 0.05302867293357849\n",
      "train auc: 0.969381\n",
      "test auc: 0.96844447\n",
      "loss at iter 60: 0.05301681160926819\n",
      "train auc: 0.969381\n",
      "test auc: 0.96844447\n",
      "loss at iter 61: 0.05300500616431236\n",
      "train auc: 0.969381\n",
      "test auc: 0.96844447\n",
      "loss at iter 62: 0.052993256598711014\n",
      "train auc: 0.969381\n",
      "test auc: 0.96844447\n",
      "loss at iter 63: 0.052981555461883545\n",
      "train auc: 0.969381\n",
      "test auc: 0.96844447\n",
      "loss at iter 64: 0.05296991392970085\n",
      "train auc: 0.969381\n",
      "test auc: 0.96844447\n",
      "loss at iter 65: 0.05295831710100174\n",
      "train auc: 0.969381\n",
      "test auc: 0.96844447\n",
      "loss at iter 66: 0.052946776151657104\n",
      "train auc: 0.969381\n",
      "test auc: 0.96844447\n",
      "loss at iter 67: 0.05293528735637665\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 68: 0.05292385071516037\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 69: 0.05291247367858887\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 70: 0.05290113389492035\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 71: 0.05288984999060631\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 72: 0.052878618240356445\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 73: 0.05286743864417076\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 74: 0.052856311202049255\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 75: 0.05284523218870163\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 76: 0.05283419415354729\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 77: 0.05282321199774742\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 78: 0.052812278270721436\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 79: 0.05280139297246933\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 80: 0.0527905598282814\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 81: 0.05277977138757706\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 82: 0.052769023925065994\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 83: 0.05275833234190941\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 84: 0.052747681736946106\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 85: 0.05273708701133728\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 86: 0.05272653326392174\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 87: 0.052716027945280075\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 88: 0.05270557105541229\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 89: 0.052695151418447495\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 90: 0.05268478766083717\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 91: 0.05267446115612984\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 92: 0.05266417935490608\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 93: 0.052653949707746506\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 94: 0.05264376103878021\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 95: 0.0526336170732975\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 96: 0.05262351408600807\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 97: 0.05261345952749252\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 98: 0.05260344594717026\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 99: 0.052593477070331573\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 100: 0.05258354917168617\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 101: 0.05257366970181465\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 102: 0.052563827484846115\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 103: 0.05255402997136116\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 104: 0.05254426971077919\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at iter 105: 0.0525345578789711\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 106: 0.05252488702535629\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 107: 0.05251525342464447\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 108: 0.05250566080212593\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 109: 0.05249611288309097\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 110: 0.0524866059422493\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 111: 0.052477143704891205\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 112: 0.0524677112698555\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 113: 0.052458327263593674\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 114: 0.052448976784944534\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 115: 0.052439671009778976\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 116: 0.052430398762226105\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 117: 0.052421171218156815\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 118: 0.05241198092699051\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 119: 0.05240282788872719\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 120: 0.05239371210336685\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 121: 0.0523846372961998\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 122: 0.05237560346722603\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 123: 0.052366603165864944\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 124: 0.052357643842697144\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 125: 0.05234871804714203\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 126: 0.0523398295044899\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 127: 0.05233098194003105\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 128: 0.05232217162847519\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 129: 0.052313391119241714\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 130: 0.05230465158820152\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 131: 0.052295953035354614\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 132: 0.052287280559539795\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 133: 0.05227864533662796\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 134: 0.05227005481719971\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 135: 0.05226149410009384\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 136: 0.052252963185310364\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 137: 0.05224447324872017\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 138: 0.05223601683974266\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 139: 0.052227601408958435\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 140: 0.0522192157804966\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 141: 0.05221085995435715\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 142: 0.05220254510641098\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 143: 0.0521942637860775\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 144: 0.052186012268066406\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 145: 0.052177794277668\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 146: 0.05216960981488228\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 147: 0.052161458879709244\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 148: 0.052153341472148895\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 149: 0.05214525759220123\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 150: 0.05213719978928566\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 151: 0.05212918668985367\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 152: 0.052121199667453766\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 153: 0.05211323872208595\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 154: 0.05210531875491142\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 155: 0.05209742486476898\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 156: 0.05208956450223923\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 157: 0.05208173766732216\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 158: 0.05207394063472748\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 159: 0.052066173404455185\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 160: 0.05205843970179558\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 161: 0.05205073207616806\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 162: 0.05204305797815323\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 163: 0.052035413682460785\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 164: 0.05202779546380043\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 165: 0.05202021449804306\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 166: 0.05201266333460808\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 167: 0.052005138248205185\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 168: 0.05199764296412468\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 169: 0.05199018120765686\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 170: 0.05198274180293083\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 171: 0.05197533965110779\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 172: 0.051967959851026535\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 173: 0.05196060240268707\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 174: 0.051953285932540894\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 175: 0.051945995539426804\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 176: 0.0519387312233448\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 177: 0.05193150043487549\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 178: 0.051924291998147964\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 179: 0.05191710963845253\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 180: 0.05190996080636978\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 181: 0.051902834326028824\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 182: 0.05189574137330055\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 183: 0.05188867077231407\n",
      "train auc: 0.96936506\n",
      "test auc: 0.9684815\n",
      "loss at iter 184: 0.05188162624835968\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 185: 0.051874611526727676\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 186: 0.05186762288212776\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 187: 0.051860660314559937\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 188: 0.0518537238240242\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 189: 0.05184681713581085\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 190: 0.05183993652462959\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 191: 0.051833078265190125\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 192: 0.051826249808073044\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 193: 0.051819443702697754\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 194: 0.05181266367435455\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 195: 0.05180591344833374\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 196: 0.05179918557405472\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 197: 0.05179248005151749\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 198: 0.05178580433130264\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 199: 0.05177915096282959\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 200: 0.051772523671388626\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 201: 0.05176592618227005\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 202: 0.051759347319602966\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 203: 0.05175279453396797\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 204: 0.05174626410007477\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 205: 0.051739756017923355\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 206: 0.05173328146338463\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 207: 0.0517268180847168\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at iter 208: 0.05172039195895195\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 209: 0.0517139807343483\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 210: 0.05170759558677673\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 211: 0.05170123279094696\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 212: 0.05169489234685898\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 213: 0.051688581705093384\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 214: 0.05168229341506958\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 215: 0.05167602002620697\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 216: 0.05166977643966675\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 217: 0.05166355520486832\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 218: 0.05165735259652138\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 219: 0.05165117233991623\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 220: 0.05164501816034317\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 221: 0.0516388900578022\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 222: 0.051632776856422424\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 223: 0.05162668973207474\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 224: 0.05162062123417854\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 225: 0.05161457508802414\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 226: 0.051608555018901825\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 227: 0.051602553576231\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 228: 0.05159657076001167\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 229: 0.05159061402082443\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 230: 0.05158468335866928\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 231: 0.05157876014709473\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 232: 0.05157287046313286\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 233: 0.051566995680332184\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 234: 0.0515611357986927\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 235: 0.05155531316995621\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 236: 0.05154949426651001\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 237: 0.0515437051653862\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 238: 0.05153793469071388\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 239: 0.051532186567783356\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 240: 0.05152645334601402\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 241: 0.05152074247598648\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 242: 0.05151505395770073\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 243: 0.05150938406586647\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 244: 0.051503736525774\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 245: 0.051498107612133026\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 246: 0.051492493599653244\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 247: 0.05148690566420555\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 248: 0.051481328904628754\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 249: 0.051475778222084045\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 250: 0.05147024616599083\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 251: 0.051464732736349106\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 252: 0.05145924165844917\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 253: 0.051453761756420135\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 254: 0.05144830420613289\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 255: 0.051442861557006836\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 256: 0.05143744498491287\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 257: 0.0514320433139801\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 258: 0.051426663994789124\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 259: 0.05142129585146904\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 260: 0.051415953785181046\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 261: 0.05141062289476395\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 262: 0.05140531063079834\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 263: 0.051400020718574524\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 264: 0.0513947457075119\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 265: 0.05138949304819107\n",
      "train auc: 0.969381\n",
      "test auc: 0.9684815\n",
      "loss at iter 266: 0.05138425529003143\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 267: 0.05137902870774269\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 268: 0.05137382820248604\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 269: 0.05136863887310028\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 270: 0.05136347562074661\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 271: 0.05135831981897354\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 272: 0.05135319009423256\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 273: 0.05134807154536247\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 274: 0.05134297534823418\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 275: 0.051337890326976776\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 276: 0.05133282393217087\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 277: 0.051327772438526154\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 278: 0.05132273957133293\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 279: 0.0513177253305912\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 280: 0.051312725991010666\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 281: 0.051307741552591324\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 282: 0.051302775740623474\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 283: 0.05129782482981682\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 284: 0.051292892545461655\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 285: 0.051287975162267685\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 286: 0.05128307268023491\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 287: 0.05127818137407303\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 288: 0.05127331241965294\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 289: 0.05126846209168434\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 290: 0.05126361921429634\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 291: 0.05125879496335983\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 292: 0.051253993064165115\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 293: 0.051249194890260696\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 294: 0.05124441906809807\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 295: 0.05123966187238693\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 296: 0.051234908401966095\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 297: 0.05123018100857735\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 298: 0.051225461065769196\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 299: 0.051220763474702835\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 300: 0.05121608078479767\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 301: 0.0512114092707634\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 302: 0.05120675265789032\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 303: 0.051202110946178436\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 304: 0.05119748413562775\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 305: 0.05119286850094795\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 306: 0.05118827149271965\n",
      "train auc: 0.9694127\n",
      "test auc: 0.9684815\n",
      "loss at iter 307: 0.051183685660362244\n",
      "train auc: 0.9694127\n",
      "test auc: 0.9684815\n",
      "loss at iter 308: 0.05117911845445633\n",
      "train auc: 0.9694127\n",
      "test auc: 0.9684815\n",
      "loss at iter 309: 0.05117456614971161\n",
      "train auc: 0.9694127\n",
      "test auc: 0.9684815\n",
      "loss at iter 310: 0.051170021295547485\n",
      "train auc: 0.9694127\n",
      "test auc: 0.9684815\n",
      "loss at iter 311: 0.051165491342544556\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 312: 0.05116098374128342\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at iter 313: 0.051156483590602875\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 314: 0.051152002066373825\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 315: 0.05114753171801567\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 316: 0.05114307254552841\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 317: 0.051138631999492645\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 318: 0.051134198904037476\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 319: 0.0511297844350338\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 320: 0.051125384867191315\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 321: 0.05112099647521973\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 322: 0.051116619259119034\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 323: 0.051112256944179535\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 324: 0.05110790953040123\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 325: 0.05110357329249382\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 326: 0.051099251955747604\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 327: 0.051094938069581985\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 328: 0.05109064653515816\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 329: 0.05108635872602463\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 330: 0.05108208954334259\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 331: 0.05107783153653145\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 332: 0.0510735884308815\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 333: 0.05106935650110245\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 334: 0.05106513574719429\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 335: 0.05106092616915703\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 336: 0.05105673521757126\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 337: 0.051052555441856384\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 338: 0.051048386842012405\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 339: 0.05104422569274902\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 340: 0.051040083169937134\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 341: 0.05103594809770584\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 342: 0.05103182792663574\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 343: 0.05102771893143654\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 344: 0.05102362483739853\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 345: 0.051019538193941116\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 346: 0.0510154664516449\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 347: 0.051011405885219574\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 348: 0.051007360219955444\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 349: 0.05100332200527191\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 350: 0.050999294966459274\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 351: 0.05099527910351753\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 352: 0.050991274416446686\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 353: 0.05098728835582733\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 354: 0.050983306020498276\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 355: 0.050979338586330414\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 356: 0.05097538232803345\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 357: 0.050971437245607376\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 358: 0.0509675033390522\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 359: 0.05096358060836792\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 360: 0.050959665328264236\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 361: 0.050955768674612045\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 362: 0.05095187574625015\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 363: 0.05094800144433975\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 364: 0.05094413086771965\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 365: 0.05094027519226074\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 366: 0.05093643069267273\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 367: 0.050932593643665314\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 368: 0.05092876777052879\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 369: 0.05092495679855347\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 370: 0.05092114955186844\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 371: 0.0509173609316349\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 372: 0.050913579761981964\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 373: 0.050909802317619324\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 374: 0.05090603977441788\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 375: 0.050902288407087326\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 376: 0.05089854821562767\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 377: 0.05089482292532921\n",
      "train auc: 0.9693968\n",
      "test auc: 0.9684815\n",
      "loss at iter 378: 0.050891097635030746\n",
      "train auc: 0.9694127\n",
      "test auc: 0.9684815\n",
      "loss at iter 379: 0.050887394696474075\n",
      "train auc: 0.9694127\n",
      "test auc: 0.9684815\n",
      "loss at iter 380: 0.050883691757917404\n",
      "train auc: 0.9694127\n",
      "test auc: 0.9684815\n",
      "loss at iter 381: 0.05088000372052193\n",
      "train auc: 0.9694127\n",
      "test auc: 0.9684815\n",
      "loss at iter 382: 0.050876326858997345\n",
      "train auc: 0.9694127\n",
      "test auc: 0.9684815\n",
      "loss at iter 383: 0.05087264999747276\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 384: 0.05086899176239967\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 385: 0.05086534470319748\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 386: 0.05086170509457588\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 387: 0.05085807293653488\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 388: 0.05085445195436478\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 389: 0.05085084214806557\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 390: 0.050847236067056656\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 391: 0.05084364488720894\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 392: 0.050840068608522415\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 393: 0.05083649232983589\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 394: 0.05083293095231056\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 395: 0.05082937702536583\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 396: 0.050825830549001694\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 397: 0.05082229524850845\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 398: 0.05081877112388611\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 399: 0.05081525072455406\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 400: 0.05081174150109291\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 401: 0.050808243453502655\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 402: 0.050804756581783295\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 403: 0.05080127716064453\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 404: 0.050797805190086365\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 405: 0.05079434812068939\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 406: 0.05079089105129242\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 407: 0.050787441432476044\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 408: 0.05078401416540146\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 409: 0.050780583173036575\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 410: 0.050777167081832886\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 411: 0.050773754715919495\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 412: 0.0507703572511673\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 413: 0.0507669672369957\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 414: 0.0507635772228241\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 415: 0.05076020583510399\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 416: 0.05075683817267418\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at iter 417: 0.050753481686115265\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 418: 0.05075013265013695\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 419: 0.05074679106473923\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 420: 0.050743456929922104\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 421: 0.050740133970975876\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 422: 0.050736818462610245\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 423: 0.05073351040482521\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 424: 0.05073021352291107\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 425: 0.05072692036628723\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 426: 0.050723642110824585\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 427: 0.05072036385536194\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 428: 0.05071709677577019\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 429: 0.05071383714675903\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 430: 0.050710588693618774\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 431: 0.050707340240478516\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 432: 0.05070411041378975\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 433: 0.050700876861810684\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 434: 0.05069766193628311\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 435: 0.05069444328546524\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 436: 0.05069124326109886\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 437: 0.05068805068731308\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 438: 0.0506848581135273\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 439: 0.05068167671561241\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 440: 0.05067850276827812\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 441: 0.05067533999681473\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 442: 0.05067218095064163\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 443: 0.050669025629758835\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 444: 0.05066588521003723\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 445: 0.050662748515605927\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 446: 0.05065962299704552\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 447: 0.050656501203775406\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 448: 0.05065338313579559\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 449: 0.050650279968976974\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 450: 0.050647176802158356\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 451: 0.05064408481121063\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 452: 0.050641003996133804\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 453: 0.050637926906347275\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 454: 0.050634849816560745\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 455: 0.05063178762793541\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 456: 0.05062873661518097\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 457: 0.05062568187713623\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 458: 0.05062263831496239\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 459: 0.05061960592865944\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 460: 0.05061657354235649\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 461: 0.05061355605721474\n",
      "train auc: 0.9694286\n",
      "test auc: 0.9684815\n",
      "loss at iter 462: 0.05061053857207298\n",
      "train auc: 0.9694286\n",
      "test auc: 0.96844447\n",
      "loss at iter 463: 0.050607528537511826\n",
      "train auc: 0.9694286\n",
      "test auc: 0.96844447\n",
      "loss at iter 464: 0.050604529678821564\n",
      "train auc: 0.9694286\n",
      "test auc: 0.96844447\n",
      "loss at iter 465: 0.0506015345454216\n",
      "train auc: 0.9694286\n",
      "test auc: 0.96844447\n",
      "loss at iter 466: 0.050598546862602234\n",
      "train auc: 0.9694286\n",
      "test auc: 0.96844447\n",
      "loss at iter 467: 0.050595566630363464\n",
      "train auc: 0.9694286\n",
      "test auc: 0.96844447\n",
      "loss at iter 468: 0.05059259012341499\n",
      "train auc: 0.9694286\n",
      "test auc: 0.96844447\n",
      "loss at iter 469: 0.050589628517627716\n",
      "train auc: 0.9694286\n",
      "test auc: 0.96844447\n",
      "loss at iter 470: 0.05058665946125984\n",
      "train auc: 0.9694286\n",
      "test auc: 0.96844447\n",
      "loss at iter 471: 0.05058370903134346\n",
      "train auc: 0.9694286\n",
      "test auc: 0.96844447\n",
      "loss at iter 472: 0.05058075860142708\n",
      "train auc: 0.9694286\n",
      "test auc: 0.96844447\n",
      "loss at iter 473: 0.05057781934738159\n",
      "train auc: 0.9694286\n",
      "test auc: 0.96844447\n",
      "loss at iter 474: 0.050574883818626404\n",
      "train auc: 0.9694286\n",
      "test auc: 0.96844447\n",
      "loss at iter 475: 0.05057195574045181\n",
      "train auc: 0.9694286\n",
      "test auc: 0.96844447\n",
      "loss at iter 476: 0.05056903511285782\n",
      "train auc: 0.9694286\n",
      "test auc: 0.96844447\n",
      "loss at iter 477: 0.050566114485263824\n",
      "train auc: 0.9694286\n",
      "test auc: 0.96844447\n",
      "loss at iter 478: 0.050563208758831024\n",
      "train auc: 0.9694286\n",
      "test auc: 0.96844447\n",
      "loss at iter 479: 0.050560303032398224\n",
      "train auc: 0.9694286\n",
      "test auc: 0.96844447\n",
      "loss at iter 480: 0.05055740848183632\n",
      "train auc: 0.9694286\n",
      "test auc: 0.96844447\n",
      "loss at iter 481: 0.05055451765656471\n",
      "train auc: 0.9694286\n",
      "test auc: 0.96844447\n",
      "loss at iter 482: 0.0505516342818737\n",
      "train auc: 0.9694286\n",
      "test auc: 0.96844447\n",
      "loss at iter 483: 0.05054875463247299\n",
      "train auc: 0.9694286\n",
      "test auc: 0.96844447\n",
      "loss at iter 484: 0.05054588243365288\n",
      "train auc: 0.9694286\n",
      "test auc: 0.96844447\n",
      "loss at iter 485: 0.05054301396012306\n",
      "train auc: 0.9694286\n",
      "test auc: 0.96844447\n",
      "loss at iter 486: 0.05054015666246414\n",
      "train auc: 0.9694286\n",
      "test auc: 0.96844447\n",
      "loss at iter 487: 0.05053730309009552\n",
      "train auc: 0.9694286\n",
      "test auc: 0.96844447\n",
      "loss at iter 488: 0.0505344532430172\n",
      "train auc: 0.9694286\n",
      "test auc: 0.96844447\n",
      "loss at iter 489: 0.05053161457180977\n",
      "train auc: 0.9694286\n",
      "test auc: 0.96844447\n",
      "loss at iter 490: 0.05052877962589264\n",
      "train auc: 0.9694286\n",
      "test auc: 0.96844447\n",
      "loss at iter 491: 0.05052594840526581\n",
      "train auc: 0.9694286\n",
      "test auc: 0.96844447\n",
      "loss at iter 492: 0.050523124635219574\n",
      "train auc: 0.9694286\n",
      "test auc: 0.96844447\n",
      "loss at iter 493: 0.05052030831575394\n",
      "train auc: 0.96944445\n",
      "test auc: 0.96844447\n",
      "loss at iter 494: 0.0505174919962883\n",
      "train auc: 0.96944445\n",
      "test auc: 0.96844447\n",
      "loss at iter 495: 0.050514690577983856\n",
      "train auc: 0.96944445\n",
      "test auc: 0.96844447\n",
      "loss at iter 496: 0.05051188915967941\n",
      "train auc: 0.96944445\n",
      "test auc: 0.96844447\n",
      "loss at iter 497: 0.050509098917245865\n",
      "train auc: 0.96944445\n",
      "test auc: 0.96844447\n",
      "loss at iter 498: 0.05050630867481232\n",
      "train auc: 0.96944445\n",
      "test auc: 0.96844447\n",
      "loss at iter 499: 0.050503525882959366\n",
      "train auc: 0.96944445\n",
      "test auc: 0.96844447\n"
     ]
    }
   ],
   "source": [
    "for i in range(500):\n",
    "    sess.run(optimizer, {input_X: train_features, input_y: train_labels})\n",
    "    loss_i = sess.run(loss, {input_X: train_features, input_y: train_labels})\n",
    "\n",
    "    print(\"loss at iter {}: {}\".format(i, loss_i))\n",
    "\n",
    "    print(\n",
    "        \"train auc:\",\n",
    "        sess.run(accuracy, feed_dict={input_X: train_features, input_y: train_labels})\n",
    "    )\n",
    "    print(\n",
    "        \"test auc:\",\n",
    "        sess.run(accuracy, feed_dict={input_X: test_features, input_y: test_labels})\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
